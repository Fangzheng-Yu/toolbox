{
    "task": "official_implementation_of_painter"  //  root/task/images-models-options
    , "model": "multiin"                          // "plain" | "multiout" | "progressive" | "multiin"
    , "gpu_ids": [6, 7]
  
    , "scale": 1       // broadcast to "netG" if SISR
    , "n_channels": 3  // broadcast to "datasets", 1 for grayscale, 3 for color
  
    , "path": {
      "root": "results/multimodal"           // "denoising" | "superresolution" | "deblurring" | "multimodel"
      , "pretrained_netG": null             // path of pretrained model
    }
  
    , "datasets": {
      "train": {
        "name": "train_dataset"             // just name
        , "dataset_type": "multimodal"      // "plain" | "plainpatch" | "multimodal"
        , "dataroot_H": null                // path of High-quality training dataset (prefered full path), for painter, use json_path_list
        , "dataroot_L": null                // path of Low-quality training dataset (prefered full path) , for painter, use json_path_list
        , "json_path_list": ["/data1/Denoising/SIDD_Srgb/denoise_ssid_train.json", 
                             "/data1/Deraining/Rain100H/derain_rain100h_train.json",
                             "/data1/Low_Light_Enhancement/LOL/enhance_lol_train.json",
                             "/data1/Depth_Estimation/NYU_Depth_V2/nyuv2_sync_image_depth.json"]
        , "H_size": [896, 448]              // patch size 40 | 64 | 96 | 128 | 192 | 224 | 256 | 384
        , "use_two_pairs": true             // in multimodal datasets, if you need one target pairs to guide the mapping 
        , "P_size": 16                      // patch size in ViT, used to calculate the window
        , "half_mask_ratio": 0.1            // half mask ratio for MAE
  
        , "dataloader_shuffle": true
        , "dataloader_num_workers": 8
        , "dataloader_batch_size": 2        // batch size 1 | 8 | 16 | 32 | 48 | 64 | 128

        , "mini_batch_sizes": [8, 5, 4, 2, 1, 1] // mini batch size for progressive training
        , "iters_milestones": [92000, 64000, 48000, 36000, 36000, 24000] // milestone of iteration for progressive training
        , "mini_H_sizes" : [128, 160, 192, 256, 320, 384] // varing H_size for progressive training
      }
      , "valid": {
        "name": "valid_dataset"           // just name
        , "dataset_type": "multimodal"      // "plain" | "plainpatch" | "multimodal"
        , "dataroot_H": null                // path of High-quality training dataset (prefered full path), for painter, use json_path_list
        , "dataroot_L": null                // path of Low-quality training dataset (prefered full path) , for painter, use json_path_list
        , "json_path_list": ["/data1/Denoising/SIDD_Srgb/denoise_ssid_val.json", 
                             "/data1/Deraining/Rain100H/derain_rain100h_val.json",
                             "/data1/Low_Light_Enhancement/LOL/enhance_lol_val.json",
                             "/data1/Depth_Estimation/NYU_Depth_V2/nyuv2_test_image_depth.json"]
        , "H_size": [896, 448]              // patch size 40 | 64 | 96 | 128 | 192 | 224 | 256 | 384
        , "use_two_pairs": true             // in multimodal datasets, if you need one target pairs to guide the mapping 
        , "P_size": 16                      // patch size in ViT, used to calculate the window
        , "half_mask_ratio": 0.1            // half mask ratio for MAE

        , "sigma": 25                     // unused
        , "sigma_valid": 25               // unused

        , "dataloader_num_workers": 8
        , "dataloader_batch_size": 2     // batch size 1 | 16 | 32 | 48 | 64 | 128
      }
      , "test": {
        "name": "test_dataset"            // unused
        , "dataset_type": "multimodal"    // dataset type
        , "dataroot_H": "/data1/Motion_Deblurring/GoPro/test/target" // path of High-quality testing dataset
        , "dataroot_L": "/data1/Motion_Deblurring/GoPro/test/input" // path of Low-quality testing dataset

        , "sigma": 25                     // unused
        , "sigma_valid": 25               // unused

        , "dataloader_num_workers": 0
        , "dataloader_batch_size": 1     // batch size 1
      }
    }
  
    , "netG": {
      "net_type": "painter"          // "mimounet" | "mimounetplus" | "restormer" | "uformer" | "nafnet"("nafnet local" for test) | "fftformer" | "painter"
      , "in_nc": 3                   // input channel number
      , "out_nc": 3                  // ouput channel number
      , "nc": 48                     // basic hidden dim or base channel and 16 for uformer_tiny
      , "nb": [6, 6, 12]             // number of blocks (list if different scales)
      , "n_refine_b": 4              // number of refinement blocks
      , "heads": [1, 2, 4, 8]        // heads of multi-head attention
      , "ffn_expansion_factor": 3    // hidden dim expanded in Gated-Dconv Network
      , "bias": false                // bias in qkv generation
      , "LayerNorm_type": "WithBias" // Other option 'BiasFree'
      , "dual_pixel_task": false     // ## True for dual-pixel defocus deblurring only. Also set inp_channels=6
      , "token_mlp": "leff"          // token of mlp in uformer
      , "enc_blk_nums": [1, 1, 1, 28]// encoder block number of nafnet
      , "dec_blk_nums": [1, 1, 1, 1] // decoder block number of nafnet
  
      , "init_type": "orthogonal"         // unused "orthogonal" | "normal" | "uniform" | "xavier_normal" | "xavier_uniform" | "kaiming_normal" | "kaiming_uniform"
      , "init_bn_type": "uniform"         // unused "uniform" | "constant"
      , "init_gain": 0.2
    }
  
    , "train": {
      "total_epoch": 15
      ,"G_lossfn_type": "smoothl1"         // "l1" | "l2sum" | "l2" | "ssim" | "psnr" | "charbonnier" | "smoothl1" | 'l1+ssim' | 'l1+fft'
      , "G_lossfn_weight": [1.0]           // default
  
      , "G_optimizer_type": "adamw"        // adam for CNN and adamw for transformer
      , "G_optimizer_lr": 1e-3             // learning rate
      , "G_optimizer_betas": [0.9, 0.999]  // beta 
      , "G_optimizer_wd": 1e-3             // weight decay
      , "G_optimizer_clipgrad": 0.01       // the max norm of grad for clipping (negative for unclipping)
  
      , "G_scheduler_type": "GradualWarmupScheduler"                      // "MultiStepLR" | "CosineAnnealingWarmRestarts" | "CosineAnnealingRestartCyclicLR" | "GradualWarmupScheduler" | "CosineAnnealingLR"
      , "G_scheduler_milestones": [5000, 10000, 20000, 25000, 30000]      // for "MultiStepLR"
      , "G_scheduler_gamma": 0.5                                          // for "MultiStepLR"
      , "G_scheduler_period": 5000                                        // for "CosineAnnealingWarmRestarts"
      , "G_scheduler_eta_min": 1e-7                                       // for "CosineAnnealingWarmRestarts"
      , "G_scheduler_periods": [9200, 20800]                              // for "CosineAnnealingRestartCyclicLR"
      , "G_scheduler_restart_weights": [1, 1]                             // for "CosineAnnealingRestartCyclicLR"
      , "G_scheduler_eta_mins": [0.0003,0.000001]                         // for "CosineAnnealingRestartCyclicLR"
      , "G_scheduler_multiplier": 1                                       // for "GradualWarmupScheduler"
      , "G_scheduler_warmup_epochs": 1                                    // for "GradualWarmupScheduler"

      , "G_regularizer_orthstep": null    // unused
      , "G_regularizer_clipstep": null    // unused
  
      , "checkpoint_valid": 5000           // for validating
      , "checkpoint_save": 5000            // for saving model
      , "checkpoint_print": 200            // for print
    }
  }
  